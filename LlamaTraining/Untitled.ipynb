{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "85bd780b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import streamlit as st\n",
    "from streamlit_chat import message\n",
    "from langchain.chains import ConversationalRetrievalChain\n",
    "from langchain.document_loaders import PyPDFLoader, DirectoryLoader\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.llms import CTransformers\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.memory import ConversationBufferMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7b71c701",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-11 20:47:04.248 \n",
      "  \u001b[33m\u001b[1mWarning:\u001b[0m to view this Streamlit app on a browser, run it with the following\n",
      "  command:\n",
      "\n",
      "    streamlit run C:\\Users\\marcos.medenou\\AppData\\Local\\anaconda3\\envs\\Llama\\lib\\site-packages\\ipykernel_launcher.py [ARGUMENTS]\n"
     ]
    },
    {
     "ename": "RepositoryNotFoundError",
     "evalue": "404 Client Error. (Request ID: Root=1-6526ede6-266074553195ad1f5d8254c3;b54d2df6-3f49-45d2-9b31-d64fab2936cc)\n\nRepository Not Found for url: https://huggingface.co/api/models/mistral-7b-instruct-v0.1.Q4_K_M.gguf/revision/main.\nPlease make sure you specified the correct `repo_id` and `repo_type`.\nIf you are trying to access a private or gated repo, make sure you are authenticated.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\envs\\Llama\\lib\\site-packages\\huggingface_hub\\utils\\_errors.py:261\u001b[0m, in \u001b[0;36mhf_raise_for_status\u001b[1;34m(response, endpoint_name)\u001b[0m\n\u001b[0;32m    260\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 261\u001b[0m     \u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraise_for_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    262\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m HTTPError \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\envs\\Llama\\lib\\site-packages\\requests\\models.py:1021\u001b[0m, in \u001b[0;36mResponse.raise_for_status\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1020\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m http_error_msg:\n\u001b[1;32m-> 1021\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m HTTPError(http_error_msg, response\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m)\n",
      "\u001b[1;31mHTTPError\u001b[0m: 404 Client Error: Not Found for url: https://huggingface.co/api/models/mistral-7b-instruct-v0.1.Q4_K_M.gguf/revision/main",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mRepositoryNotFoundError\u001b[0m                   Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 48\u001b[0m\n\u001b[0;32m     45\u001b[0m vector_store \u001b[38;5;241m=\u001b[39m create_vector_store(text_chunks, embeddings)\n\u001b[0;32m     47\u001b[0m \u001b[38;5;66;03m# Create LLMS model\u001b[39;00m\n\u001b[1;32m---> 48\u001b[0m llm \u001b[38;5;241m=\u001b[39m \u001b[43mcreate_llms_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     50\u001b[0m \u001b[38;5;66;03m# Initialize conversation history\u001b[39;00m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhistory\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m st\u001b[38;5;241m.\u001b[39msession_state:\n",
      "Cell \u001b[1;32mIn[2], line 25\u001b[0m, in \u001b[0;36mcreate_llms_model\u001b[1;34m()\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate_llms_model\u001b[39m():\n\u001b[1;32m---> 25\u001b[0m     llm \u001b[38;5;241m=\u001b[39m \u001b[43mCTransformers\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmistral-7b-instruct-v0.1.Q4_K_M.gguf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmax_new_tokens\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m128\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtemperature\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.01\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     26\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m llm\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\envs\\Llama\\lib\\site-packages\\langchain\\load\\serializable.py:97\u001b[0m, in \u001b[0;36mSerializable.__init__\u001b[1;34m(self, **kwargs)\u001b[0m\n\u001b[0;32m     96\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m---> 97\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     98\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lc_kwargs \u001b[38;5;241m=\u001b[39m kwargs\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\envs\\Llama\\lib\\site-packages\\pydantic\\v1\\main.py:339\u001b[0m, in \u001b[0;36mBaseModel.__init__\u001b[1;34m(__pydantic_self__, **data)\u001b[0m\n\u001b[0;32m    333\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    334\u001b[0m \u001b[38;5;124;03mCreate a new model by parsing and validating input data from keyword arguments.\u001b[39;00m\n\u001b[0;32m    335\u001b[0m \n\u001b[0;32m    336\u001b[0m \u001b[38;5;124;03mRaises ValidationError if the input data cannot be parsed to form a valid model.\u001b[39;00m\n\u001b[0;32m    337\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    338\u001b[0m \u001b[38;5;66;03m# Uses something other than `self` the first arg to allow \"self\" as a settable attribute\u001b[39;00m\n\u001b[1;32m--> 339\u001b[0m values, fields_set, validation_error \u001b[38;5;241m=\u001b[39m \u001b[43mvalidate_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43m__pydantic_self__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;18;43m__class__\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    340\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m validation_error:\n\u001b[0;32m    341\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m validation_error\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\envs\\Llama\\lib\\site-packages\\pydantic\\v1\\main.py:1102\u001b[0m, in \u001b[0;36mvalidate_model\u001b[1;34m(model, input_data, cls)\u001b[0m\n\u001b[0;32m   1100\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m   1101\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1102\u001b[0m     values \u001b[38;5;241m=\u001b[39m \u001b[43mvalidator\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcls_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1103\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mValueError\u001b[39;00m, \u001b[38;5;167;01mTypeError\u001b[39;00m, \u001b[38;5;167;01mAssertionError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[0;32m   1104\u001b[0m     errors\u001b[38;5;241m.\u001b[39mappend(ErrorWrapper(exc, loc\u001b[38;5;241m=\u001b[39mROOT_KEY))\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\envs\\Llama\\lib\\site-packages\\langchain\\llms\\ctransformers.py:72\u001b[0m, in \u001b[0;36mCTransformers.validate_environment\u001b[1;34m(cls, values)\u001b[0m\n\u001b[0;32m     66\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\n\u001b[0;32m     67\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCould not import `ctransformers` package. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     68\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease install it with `pip install ctransformers`\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     69\u001b[0m     )\n\u001b[0;32m     71\u001b[0m config \u001b[38;5;241m=\u001b[39m values[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconfig\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;129;01mor\u001b[39;00m {}\n\u001b[1;32m---> 72\u001b[0m values[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclient\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m AutoModelForCausalLM\u001b[38;5;241m.\u001b[39mfrom_pretrained(\n\u001b[0;32m     73\u001b[0m     values[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m     74\u001b[0m     model_type\u001b[38;5;241m=\u001b[39mvalues[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel_type\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m     75\u001b[0m     model_file\u001b[38;5;241m=\u001b[39mvalues[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel_file\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m     76\u001b[0m     lib\u001b[38;5;241m=\u001b[39mvalues[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlib\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m     77\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig,\n\u001b[0;32m     78\u001b[0m )\n\u001b[0;32m     79\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m values\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\envs\\Llama\\lib\\site-packages\\ctransformers\\hub.py:151\u001b[0m, in \u001b[0;36mAutoModelForCausalLM.from_pretrained\u001b[1;34m(cls, model_path_or_repo_id, model_type, model_file, config, lib, local_files_only, revision, hf, **kwargs)\u001b[0m\n\u001b[0;32m    142\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m gptq\n\u001b[0;32m    144\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m gptq\u001b[38;5;241m.\u001b[39mAutoModelForCausalLM\u001b[38;5;241m.\u001b[39mfrom_pretrained(\n\u001b[0;32m    145\u001b[0m         model_path_or_repo_id,\n\u001b[0;32m    146\u001b[0m         local_files_only\u001b[38;5;241m=\u001b[39mlocal_files_only,\n\u001b[0;32m    147\u001b[0m         revision\u001b[38;5;241m=\u001b[39mrevision,\n\u001b[0;32m    148\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    149\u001b[0m     )\n\u001b[1;32m--> 151\u001b[0m config \u001b[38;5;241m=\u001b[39m config \u001b[38;5;129;01mor\u001b[39;00m AutoConfig\u001b[38;5;241m.\u001b[39mfrom_pretrained(\n\u001b[0;32m    152\u001b[0m     model_path_or_repo_id,\n\u001b[0;32m    153\u001b[0m     local_files_only\u001b[38;5;241m=\u001b[39mlocal_files_only,\n\u001b[0;32m    154\u001b[0m     revision\u001b[38;5;241m=\u001b[39mrevision,\n\u001b[0;32m    155\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    156\u001b[0m )\n\u001b[0;32m    157\u001b[0m model_type \u001b[38;5;241m=\u001b[39m model_type \u001b[38;5;129;01mor\u001b[39;00m config\u001b[38;5;241m.\u001b[39mmodel_type\n\u001b[0;32m    159\u001b[0m path_type \u001b[38;5;241m=\u001b[39m get_path_type(model_path_or_repo_id)\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\envs\\Llama\\lib\\site-packages\\ctransformers\\hub.py:48\u001b[0m, in \u001b[0;36mAutoConfig.from_pretrained\u001b[1;34m(cls, model_path_or_repo_id, local_files_only, revision, **kwargs)\u001b[0m\n\u001b[0;32m     46\u001b[0m     \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_update_from_dir(model_path_or_repo_id, auto_config)\n\u001b[0;32m     47\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m path_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrepo\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m---> 48\u001b[0m     \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_update_from_repo\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     49\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel_path_or_repo_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     50\u001b[0m \u001b[43m        \u001b[49m\u001b[43mauto_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     51\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     52\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrevision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     53\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m kwargs\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m     56\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(config, k):\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\envs\\Llama\\lib\\site-packages\\ctransformers\\hub.py:72\u001b[0m, in \u001b[0;36mAutoConfig._update_from_repo\u001b[1;34m(cls, repo_id, auto_config, local_files_only, revision)\u001b[0m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[0;32m     65\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_update_from_repo\u001b[39m(\n\u001b[0;32m     66\u001b[0m     \u001b[38;5;28mcls\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     70\u001b[0m     revision: Optional[\u001b[38;5;28mstr\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m     71\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m---> 72\u001b[0m     path \u001b[38;5;241m=\u001b[39m \u001b[43msnapshot_download\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     73\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrepo_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrepo_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     74\u001b[0m \u001b[43m        \u001b[49m\u001b[43mallow_patterns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mconfig.json\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     75\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     76\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrevision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     77\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     78\u001b[0m     \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_update_from_dir(path, auto_config)\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\envs\\Llama\\lib\\site-packages\\huggingface_hub\\utils\\_validators.py:118\u001b[0m, in \u001b[0;36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    115\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m check_use_auth_token:\n\u001b[0;32m    116\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m smoothly_deprecate_use_auth_token(fn_name\u001b[38;5;241m=\u001b[39mfn\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, has_token\u001b[38;5;241m=\u001b[39mhas_token, kwargs\u001b[38;5;241m=\u001b[39mkwargs)\n\u001b[1;32m--> 118\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\envs\\Llama\\lib\\site-packages\\huggingface_hub\\_snapshot_download.py:189\u001b[0m, in \u001b[0;36msnapshot_download\u001b[1;34m(repo_id, repo_type, revision, endpoint, cache_dir, local_dir, local_dir_use_symlinks, library_name, library_version, user_agent, proxies, etag_timeout, resume_download, force_download, token, local_files_only, allow_patterns, ignore_patterns, max_workers, tqdm_class)\u001b[0m\n\u001b[0;32m    187\u001b[0m \u001b[38;5;66;03m# if we have internet connection we retrieve the correct folder name from the huggingface api\u001b[39;00m\n\u001b[0;32m    188\u001b[0m api \u001b[38;5;241m=\u001b[39m HfApi(library_name\u001b[38;5;241m=\u001b[39mlibrary_name, library_version\u001b[38;5;241m=\u001b[39mlibrary_version, user_agent\u001b[38;5;241m=\u001b[39muser_agent, endpoint\u001b[38;5;241m=\u001b[39mendpoint)\n\u001b[1;32m--> 189\u001b[0m repo_info \u001b[38;5;241m=\u001b[39m \u001b[43mapi\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrepo_info\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrepo_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrepo_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrepo_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrepo_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrevision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    190\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m repo_info\u001b[38;5;241m.\u001b[39msha \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRepo info returned from server must have a revision sha.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    192\u001b[0m filtered_repo_files \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\n\u001b[0;32m    193\u001b[0m     filter_repo_objects(\n\u001b[0;32m    194\u001b[0m         items\u001b[38;5;241m=\u001b[39m[f\u001b[38;5;241m.\u001b[39mrfilename \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m repo_info\u001b[38;5;241m.\u001b[39msiblings],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    197\u001b[0m     )\n\u001b[0;32m    198\u001b[0m )\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\envs\\Llama\\lib\\site-packages\\huggingface_hub\\utils\\_validators.py:118\u001b[0m, in \u001b[0;36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    115\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m check_use_auth_token:\n\u001b[0;32m    116\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m smoothly_deprecate_use_auth_token(fn_name\u001b[38;5;241m=\u001b[39mfn\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, has_token\u001b[38;5;241m=\u001b[39mhas_token, kwargs\u001b[38;5;241m=\u001b[39mkwargs)\n\u001b[1;32m--> 118\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\envs\\Llama\\lib\\site-packages\\huggingface_hub\\hf_api.py:1888\u001b[0m, in \u001b[0;36mHfApi.repo_info\u001b[1;34m(self, repo_id, revision, repo_type, timeout, files_metadata, token)\u001b[0m\n\u001b[0;32m   1886\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1887\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnsupported repo type.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m-> 1888\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmethod\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1889\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrepo_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1890\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrevision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1891\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1892\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1893\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiles_metadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfiles_metadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1894\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\envs\\Llama\\lib\\site-packages\\huggingface_hub\\utils\\_validators.py:118\u001b[0m, in \u001b[0;36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    115\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m check_use_auth_token:\n\u001b[0;32m    116\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m smoothly_deprecate_use_auth_token(fn_name\u001b[38;5;241m=\u001b[39mfn\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, has_token\u001b[38;5;241m=\u001b[39mhas_token, kwargs\u001b[38;5;241m=\u001b[39mkwargs)\n\u001b[1;32m--> 118\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\envs\\Llama\\lib\\site-packages\\huggingface_hub\\hf_api.py:1698\u001b[0m, in \u001b[0;36mHfApi.model_info\u001b[1;34m(self, repo_id, revision, timeout, securityStatus, files_metadata, token)\u001b[0m\n\u001b[0;32m   1696\u001b[0m     params[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mblobs\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m   1697\u001b[0m r \u001b[38;5;241m=\u001b[39m get_session()\u001b[38;5;241m.\u001b[39mget(path, headers\u001b[38;5;241m=\u001b[39mheaders, timeout\u001b[38;5;241m=\u001b[39mtimeout, params\u001b[38;5;241m=\u001b[39mparams)\n\u001b[1;32m-> 1698\u001b[0m \u001b[43mhf_raise_for_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43mr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1699\u001b[0m d \u001b[38;5;241m=\u001b[39m r\u001b[38;5;241m.\u001b[39mjson()\n\u001b[0;32m   1700\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m ModelInfo(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39md)\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\envs\\Llama\\lib\\site-packages\\huggingface_hub\\utils\\_errors.py:293\u001b[0m, in \u001b[0;36mhf_raise_for_status\u001b[1;34m(response, endpoint_name)\u001b[0m\n\u001b[0;32m    279\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m error_code \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRepoNotFound\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m response\u001b[38;5;241m.\u001b[39mstatus_code \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m401\u001b[39m:\n\u001b[0;32m    280\u001b[0m     \u001b[38;5;66;03m# 401 is misleading as it is returned for:\u001b[39;00m\n\u001b[0;32m    281\u001b[0m     \u001b[38;5;66;03m#    - private and gated repos if user is not authenticated\u001b[39;00m\n\u001b[0;32m    282\u001b[0m     \u001b[38;5;66;03m#    - missing repos\u001b[39;00m\n\u001b[0;32m    283\u001b[0m     \u001b[38;5;66;03m# => for now, we process them as `RepoNotFound` anyway.\u001b[39;00m\n\u001b[0;32m    284\u001b[0m     \u001b[38;5;66;03m# See https://gist.github.com/Wauplin/46c27ad266b15998ce56a6603796f0b9\u001b[39;00m\n\u001b[0;32m    285\u001b[0m     message \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    286\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresponse\u001b[38;5;241m.\u001b[39mstatus_code\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m Client Error.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    287\u001b[0m         \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    291\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m make sure you are authenticated.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    292\u001b[0m     )\n\u001b[1;32m--> 293\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m RepositoryNotFoundError(message, response) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[0;32m    295\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m response\u001b[38;5;241m.\u001b[39mstatus_code \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m400\u001b[39m:\n\u001b[0;32m    296\u001b[0m     message \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    297\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mBad request for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mendpoint_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m endpoint:\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m endpoint_name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mBad request:\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    298\u001b[0m     )\n",
      "\u001b[1;31mRepositoryNotFoundError\u001b[0m: 404 Client Error. (Request ID: Root=1-6526ede6-266074553195ad1f5d8254c3;b54d2df6-3f49-45d2-9b31-d64fab2936cc)\n\nRepository Not Found for url: https://huggingface.co/api/models/mistral-7b-instruct-v0.1.Q4_K_M.gguf/revision/main.\nPlease make sure you specified the correct `repo_id` and `repo_type`.\nIf you are trying to access a private or gated repo, make sure you are authenticated."
     ]
    }
   ],
   "source": [
    "\n",
    "# Function to load documents \n",
    "def load_documents():\n",
    "    loader = DirectoryLoader('data/', glob=\"*.pdf\", loader_cls=PyPDFLoader)\n",
    "    documents = loader.load()\n",
    "    return documents\n",
    "\n",
    "# Function to split text into chunks\n",
    "def split_text_into_chunks(documents):\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50)\n",
    "    text_chunks = text_splitter.split_documents(documents)\n",
    "    return text_chunks\n",
    "\n",
    "# Function to create embeddings\n",
    "def create_embeddings():\n",
    "    embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\", model_kwargs={'device': \"cpu\"})\n",
    "    return embeddings\n",
    "\n",
    "# Function to create vector store\n",
    "def create_vector_store(text_chunks, embeddings):\n",
    "    vector_store = FAISS.from_documents(text_chunks, embeddings)\n",
    "    return vector_store\n",
    "\n",
    "# Function to create LLMS model\n",
    "def create_llms_model():\n",
    "    llm = CTransformers(model=\"mistral-7b-instruct-v0.1.Q4_K_M.gguf\", config={'max_new_tokens': 128, 'temperature': 0.01})\n",
    "    return llm\n",
    "\n",
    "# Initialize Streamlit app\n",
    "st.title(\"Job Interview Prep ChatBot\")\n",
    "st.title(\"Personalized Job Success Friend\")\n",
    "st.markdown('<style>h1{color: orange; text-align: center;}</style>', unsafe_allow_html=True)\n",
    "st.subheader('Get Your Desired Job ðŸ’ª')\n",
    "st.markdown('<style>h3{color: pink; text-align: center;}</style>', unsafe_allow_html=True)\n",
    "\n",
    "# loading of documents\n",
    "documents = load_documents()\n",
    "\n",
    "# Split text into chunks\n",
    "text_chunks = split_text_into_chunks(documents)\n",
    "\n",
    "# Create embeddings\n",
    "embeddings = create_embeddings()\n",
    "\n",
    "# Create vector store\n",
    "vector_store = create_vector_store(text_chunks, embeddings)\n",
    "\n",
    "# Create LLMS model\n",
    "llm = create_llms_model()\n",
    "\n",
    "# Initialize conversation history\n",
    "if 'history' not in st.session_state:\n",
    "    st.session_state['history'] = []\n",
    "\n",
    "if 'generated' not in st.session_state:\n",
    "    st.session_state['generated'] = [\"Hello! Ask me anything about ðŸ¤—\"]\n",
    "\n",
    "if 'past' not in st.session_state:\n",
    "    st.session_state['past'] = [\"Hey! ðŸ‘‹\"]\n",
    "\n",
    "# Create memory\n",
    "memory = ConversationBufferMemory(memory_key=\"chat_history\", return_messages=True)\n",
    "\n",
    "# Create chain\n",
    "chain = ConversationalRetrievalChain.from_llm(llm=llm, chain_type='stuff',\n",
    "                                              retriever=vector_store.as_retriever(search_kwargs={\"k\": 2}),\n",
    "                                              memory=memory)\n",
    "\n",
    "# Define chat function\n",
    "def conversation_chat(query):\n",
    "    result = chain({\"question\": query, \"chat_history\": st.session_state['history']})\n",
    "    st.session_state['history'].append((query, result[\"answer\"]))\n",
    "    return result[\"answer\"]\n",
    "\n",
    "# Display chat history\n",
    "reply_container = st.container()\n",
    "container = st.container()\n",
    "\n",
    "with container:\n",
    "    with st.form(key='my_form', clear_on_submit=True):\n",
    "        user_input = st.text_input(\"Question:\", placeholder=\"Ask about your Job Interview\", key='input')\n",
    "        submit_button = st.form_submit_button(label='Send')\n",
    "\n",
    "    if submit_button and user_input:\n",
    "        output = conversation_chat(user_input)\n",
    "        st.session_state['past'].append(user_input)\n",
    "        st.session_state['generated'].append(output)\n",
    "\n",
    "if st.session_state['generated']:\n",
    "    with reply_container:\n",
    "        for i in range(len(st.session_state['generated'])):\n",
    "            message(st.session_state[\"past\"][i], is_user=True, key=str(i) + '_user', avatar_style=\"thumbs\")\n",
    "            message(st.session_state[\"generated\"][i], key=str(i), avatar_style=\"fun-emoji\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef3319e6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
